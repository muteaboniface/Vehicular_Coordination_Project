{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Storage\n",
    "The Aim of this notebook is to extract relevant data that pertains the scope of this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "From the <strong>Vehicular_coordination_Visualization Notebook </strong> it is clear that the datasets contain a significant number of information that might not be necessary in the prediction of lane change maneuvres.\n",
    "\n",
    "For that reason, necessary columns are selcted which are to be used in the training and evaluation of the model.\n",
    "\n",
    "It is important to note that some of the techniques used in this notebook have been inferenced from the <a href = \"https://github.com/RobertKrajewski/highD-dataset\"> HighD dataset tools</a> that are provided together with the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing requisite libraries and classes.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns to extract from the dataset files are as provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACK FILE\n",
    "BBOX = \"bbox\"\n",
    "FRAMES = \"frames\"\n",
    "FRAME = \"frame\"\n",
    "TRACK_ID = \"id\"\n",
    "X = \"x\"\n",
    "Y = \"y\"\n",
    "WIDTH = \"width\"\n",
    "HEIGHT = \"height\"\n",
    "X_VELOCITY = \"xVelocity\"\n",
    "Y_VELOCITY = \"yVelocity\"\n",
    "X_ACCELERATION = \"xAcceleration\"\n",
    "Y_ACCELERATION = \"yAcceleration\"\n",
    "FRONT_SIGHT_DISTANCE = \"frontSightDistance\"\n",
    "BACK_SIGHT_DISTANCE = \"backSightDistance\"\n",
    "DHW = \"dhw\"\n",
    "THW = \"thw\"\n",
    "TTC = \"ttc\"\n",
    "PRECEDING_X_VELOCITY = \"precedingXVelocity\"\n",
    "PRECEDING_ID = \"precedingId\"\n",
    "FOLLOWING_ID = \"followingId\"\n",
    "LEFT_PRECEDING_ID = \"leftPrecedingId\"\n",
    "LEFT_ALONGSIDE_ID = \"leftAlongsideId\"\n",
    "LEFT_FOLLOWING_ID = \"leftFollowingId\"\n",
    "RIGHT_PRECEDING_ID = \"rightPrecedingId\"\n",
    "RIGHT_ALONGSIDE_ID = \"rightAlongsideId\"\n",
    "RIGHT_FOLLOWING_ID = \"rightFollowingId\"\n",
    "LANE_ID = \"laneId\"\n",
    "\n",
    "# STATIC FILE\n",
    "INITIAL_FRAME = \"initialFrame\"\n",
    "FINAL_FRAME = \"finalFrame\"\n",
    "NUM_FRAMES = \"numFrames\"\n",
    "CLASS = \"class\"\n",
    "DRIVING_DIRECTION = \"drivingDirection\"\n",
    "TRAVELED_DISTANCE = \"traveledDistance\"\n",
    "MIN_X_VELOCITY = \"minXVelocity\"\n",
    "MAX_X_VELOCITY = \"maxXVelocity\"\n",
    "MEAN_X_VELOCITY = \"meanXVelocity\"\n",
    "MIN_DHW = \"minDHW\"\n",
    "MIN_THW = \"minTHW\"\n",
    "MIN_TTC = \"minTTC\"\n",
    "NUMBER_LANE_CHANGES = \"numLaneChanges\"\n",
    "\n",
    "# RECORDING META\n",
    "ID = \"id\"\n",
    "FRAME_RATE = \"frameRate\"\n",
    "LOCATION_ID = \"locationId\"\n",
    "SPEED_LIMIT = \"speedLimit\"\n",
    "MONTH = \"month\"\n",
    "WEEKDAY = \"weekDay\"\n",
    "START_TIME = \"startTime\"\n",
    "DURATION = \"duration\"\n",
    "TOTAL_DRIVEN_DISTANCE = \"totalDrivenDistance\"\n",
    "TOTAL_DRIVEN_TIME = \"totalDrivenTime\"\n",
    "N_VEHICLES = \"numVehicles\"\n",
    "N_CARS = \"numCars\"\n",
    "N_TRUCKS = \"numTrucks\"\n",
    "UPPER_LANE_MARKINGS = \"upperLaneMarkings\"\n",
    "LOWER_LANE_MARKINGS = \"lowerLaneMarkings\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definations\n",
    "    These Functions help read data and extract it in a dictionary format for easier handling in the preceeding steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tracks(track_csv_path):\n",
    "    \"\"\"\n",
    "    This method reads a provided track file from the dataset\n",
    "\n",
    "    :param arguments: input file path to the track file information\n",
    "    \n",
    "    :Return: a dictionary containing all tracks with the Id as the key\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the csv file\n",
    "    df = pd.read_csv(track_csv_path)\n",
    "\n",
    "    # Use groupby to aggregate track info. Less error prone than iterating over the data.\n",
    "    grouped = df.groupby([TRACK_ID], sort=False)\n",
    "    # pre-allocate an empty dictionary\n",
    "    tracks = {}\n",
    "    current_track = 0\n",
    "    \n",
    "    # Extract the necessary track information !!! All info used currently\n",
    "    \n",
    "    for group_id, rows in grouped:\n",
    "        # create the vehicles bounding box. Defines the vehicle dimensions.\n",
    "        bounding_boxes = np.transpose(np.array([rows[X].values,\n",
    "                                                rows[Y].values,\n",
    "                                                rows[WIDTH].values,\n",
    "                                                rows[HEIGHT].values]))\n",
    "        \n",
    "        \n",
    "        tracks[np.int64(group_id)] = {\n",
    "            FRAME: rows[FRAME].values,\n",
    "            X: rows[X].values,\n",
    "            Y: rows[Y].values,\n",
    "            BBOX: bounding_boxes,\n",
    "            X_VELOCITY: rows[X_VELOCITY].values,\n",
    "            Y_VELOCITY: rows[Y_VELOCITY].values,\n",
    "            X_ACCELERATION: rows[X_ACCELERATION].values,\n",
    "            Y_ACCELERATION: rows[Y_ACCELERATION].values,\n",
    "            FRONT_SIGHT_DISTANCE: rows[FRONT_SIGHT_DISTANCE].values,\n",
    "            BACK_SIGHT_DISTANCE: rows[BACK_SIGHT_DISTANCE].values,\n",
    "            THW: rows[THW].values,\n",
    "            TTC: rows[TTC].values,\n",
    "            DHW: rows[DHW].values,\n",
    "            PRECEDING_X_VELOCITY: rows[PRECEDING_X_VELOCITY].values,\n",
    "            PRECEDING_ID: rows[PRECEDING_ID].values,\n",
    "            FOLLOWING_ID: rows[FOLLOWING_ID].values,\n",
    "            LEFT_FOLLOWING_ID: rows[LEFT_FOLLOWING_ID].values,\n",
    "            LEFT_ALONGSIDE_ID: rows[LEFT_ALONGSIDE_ID].values,\n",
    "            LEFT_PRECEDING_ID: rows[LEFT_PRECEDING_ID].values,\n",
    "            RIGHT_FOLLOWING_ID: rows[RIGHT_FOLLOWING_ID].values,\n",
    "            RIGHT_ALONGSIDE_ID: rows[RIGHT_ALONGSIDE_ID].values,\n",
    "            RIGHT_PRECEDING_ID: rows[RIGHT_PRECEDING_ID].values,\n",
    "            LANE_ID: rows[LANE_ID].values\n",
    "        }\n",
    "        current_track = current_track + 1\n",
    "        \n",
    "    print(\"Finished Extracting Tracks Data\")\n",
    "    return tracks\n",
    "\n",
    "\n",
    "          \n",
    "def read_tracks_meta(tracks_metadata_path):\n",
    "    \"\"\"\n",
    "    Reads the XX_tracksMeta.csv file from the dataset\n",
    "\n",
    "    :param arguments: input file path to the tracksMeta file\n",
    "    \n",
    "    :return: the static dictionary - the key is the track_id and the value is the corresponding data for this track\n",
    "    \"\"\"\n",
    "    # Read the csv file\n",
    "    df = pd.read_csv(tracks_metadata_path)\n",
    "\n",
    "    # Initialize the static_dictionary\n",
    "    metadata_dictionary = {}\n",
    "\n",
    "    # Iterate over all rows of the csv because we need to create the bounding boxes for each row\n",
    "    for i_row in range(df.shape[0]):\n",
    "        track_id = int(df[TRACK_ID][i_row])\n",
    "        metadata_dictionary[track_id] = {TRACK_ID: track_id,\n",
    "                                       WIDTH: float(df[WIDTH][i_row]),\n",
    "                                       HEIGHT: float(df[HEIGHT][i_row]),\n",
    "                                       INITIAL_FRAME: int(df[INITIAL_FRAME][i_row]),\n",
    "                                       FINAL_FRAME: int(df[FINAL_FRAME][i_row]),\n",
    "                                       NUM_FRAMES: int(df[NUM_FRAMES][i_row]),\n",
    "                                       CLASS: str(df[CLASS][i_row]),\n",
    "                                       DRIVING_DIRECTION: float(df[DRIVING_DIRECTION][i_row]),\n",
    "                                       TRAVELED_DISTANCE: float(df[TRAVELED_DISTANCE][i_row]),\n",
    "                                       MIN_X_VELOCITY: float(df[MIN_X_VELOCITY][i_row]),\n",
    "                                       MAX_X_VELOCITY: float(df[MAX_X_VELOCITY][i_row]),\n",
    "                                       MEAN_X_VELOCITY: float(df[MEAN_X_VELOCITY][i_row]),\n",
    "                                       MIN_TTC: float(df[MIN_TTC][i_row]),\n",
    "                                       MIN_THW: float(df[MIN_THW][i_row]),\n",
    "                                       MIN_DHW: float(df[MIN_DHW][i_row]),\n",
    "                                       NUMBER_LANE_CHANGES: int(\n",
    "                                           df[NUMBER_LANE_CHANGES][i_row])\n",
    "                                       }\n",
    "          \n",
    "    print(\"Finished Extracting Tracks_Metadata\")\n",
    "    return metadata_dictionary\n",
    "\n",
    "\n",
    "def read_recording_meta(recording_meta_path):\n",
    "    \"\"\"\n",
    "    This method reads the Recording meta file from the dataset : XX_recordingMeta.csv\n",
    "\n",
    "    :param arguments: input path to the XX_recordingMeta.csv file\n",
    "    \n",
    "    :return: the meta dictionary containing the general information of the video\n",
    "    \"\"\"\n",
    "          \n",
    "    # Read the csv file\n",
    "    df = pd.read_csv(recording_meta_path)\n",
    "\n",
    "    # Extract the information from the files and store the to below variable      \n",
    "    extracted_meta_dictionary = {ID: int(df[ID][0]),\n",
    "                                 FRAME_RATE: int(df[FRAME_RATE][0]),\n",
    "                                 LOCATION_ID: int(df[LOCATION_ID][0]),\n",
    "                                 SPEED_LIMIT: float(df[SPEED_LIMIT][0]),\n",
    "                                 MONTH: str(df[MONTH][0]),\n",
    "                                 WEEKDAY: str(df[WEEKDAY][0]),\n",
    "                                 START_TIME: str(df[START_TIME][0]),\n",
    "                                 DURATION: float(df[DURATION][0]),\n",
    "                                 TOTAL_DRIVEN_DISTANCE: float(df[TOTAL_DRIVEN_DISTANCE][0]),\n",
    "                                 TOTAL_DRIVEN_TIME: float(df[TOTAL_DRIVEN_TIME][0]),\n",
    "                                 N_VEHICLES: int(df[N_VEHICLES][0]),\n",
    "                                 N_CARS: int(df[N_CARS][0]),\n",
    "                                 N_TRUCKS: int(df[N_TRUCKS][0]),\n",
    "                                 UPPER_LANE_MARKINGS: np.fromstring(df[UPPER_LANE_MARKINGS][0], sep=\";\"),\n",
    "                                 LOWER_LANE_MARKINGS: np.fromstring(df[LOWER_LANE_MARKINGS][0], sep=\";\")}\n",
    "          \n",
    "    print(\"Finished Extracting Recording_Metadata\")\n",
    "    return extracted_meta_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data and store in a pickle file for easier retrieval and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_TAKEN = 50  # number of states to construct features\n",
    "FRAME_BEFORE = 12  # frame taken before the lane change\n",
    "FRAME_BEFORE_FLAG = False # use FRAME_BEFORE or not\n",
    "\n",
    "def run(number):\n",
    "    '''\n",
    "    This function runs the data processing code and output to pickle files\n",
    "    '''\n",
    "    # Read the three different files\n",
    "    tracks_csv = read_tracks(\"data/\" + number + \"_tracks.csv\")\n",
    "    tracks_meta = read_tracks_meta(\"data/\" + number + \"_tracksMeta.csv\")\n",
    "    recording_meta = read_recording_meta(\"data/\" + number + \"_recordingMeta.csv\")\n",
    "    \n",
    "    \n",
    "    # Obtain the lane changing cars and lane keeping cars\n",
    "    lane_changing_ids = []\n",
    "    lane_keeping_ids = []\n",
    "    \n",
    "    for key in tracks_meta:\n",
    "        if(tracks_meta[key][NUMBER_LANE_CHANGES] > 0):\n",
    "            lane_changing_ids.append(key)\n",
    "        else:\n",
    "            lane_keeping_ids.append(key)\n",
    "\n",
    "            \n",
    "    # get the lane information\n",
    "    lanes_info = {}\n",
    "    # Two lane are removed since the top most and bottom most files are not usually used\n",
    "    lane_num = len(recording_meta[UPPER_LANE_MARKINGS]) + \\\n",
    "        len(recording_meta[LOWER_LANE_MARKINGS]) - 2\n",
    "    # Associating the lanes as per the context, by eliminating the unused lanes\n",
    "    if lane_num == 4:\n",
    "        # 4 lanes. get rid of lanes 1 and 4\n",
    "        lanes_info[2] = recording_meta[UPPER_LANE_MARKINGS][0]\n",
    "        lanes_info[3] = recording_meta[UPPER_LANE_MARKINGS][1]\n",
    "        lanes_info[5] = recording_meta[LOWER_LANE_MARKINGS][0]\n",
    "        lanes_info[6] = recording_meta[LOWER_LANE_MARKINGS][1]\n",
    "        lane_width = ((lanes_info[3] - lanes_info[2]) +\n",
    "                      (lanes_info[6] - lanes_info[5])) / 2\n",
    "    elif lane_num == 6:\n",
    "        # 6 lanes. get rid of lanes 1,5\n",
    "        lanes_info[2] = recording_meta[UPPER_LANE_MARKINGS][0]\n",
    "        lanes_info[3] = recording_meta[UPPER_LANE_MARKINGS][1]\n",
    "        lanes_info[4] = recording_meta[UPPER_LANE_MARKINGS][2]\n",
    "        lanes_info[6] = recording_meta[LOWER_LANE_MARKINGS][0]\n",
    "        lanes_info[7] = recording_meta[LOWER_LANE_MARKINGS][1]\n",
    "        lanes_info[8] = recording_meta[LOWER_LANE_MARKINGS][2]\n",
    "        lane_width = ((lanes_info[3] - lanes_info[2]) + (lanes_info[4] - lanes_info[3]) +\n",
    "                      (lanes_info[7] - lanes_info[6]) + (lanes_info[8] - lanes_info[7])) / 4\n",
    "    elif lane_num == 7:\n",
    "        # 7 lanes: track 58 ~ 60 . get rid of lanes 1,6\n",
    "        lanes_info[2] = recording_meta[UPPER_LANE_MARKINGS][0]\n",
    "        lanes_info[3] = recording_meta[UPPER_LANE_MARKINGS][1]\n",
    "        lanes_info[4] = recording_meta[UPPER_LANE_MARKINGS][2]\n",
    "        lanes_info[5] = recording_meta[UPPER_LANE_MARKINGS][3]\n",
    "        lanes_info[7] = recording_meta[LOWER_LANE_MARKINGS][0]\n",
    "        lanes_info[8] = recording_meta[LOWER_LANE_MARKINGS][1]\n",
    "        lanes_info[9] = recording_meta[LOWER_LANE_MARKINGS][2]\n",
    "        lane_width = ((lanes_info[3] - lanes_info[2]) + (lanes_info[4] - lanes_info[3]) + (\n",
    "            lanes_info[5] - lanes_info[4]) + (lanes_info[8] - lanes_info[7]) + (lanes_info[9] - lanes_info[8])) / 5\n",
    "    else:\n",
    "        print(\"Error: Unrecognized input file number -\", number)\n",
    "\n",
    "        \n",
    "        \n",
    "    def determine_lane_exist(cur_lane):\n",
    "        '''\n",
    "        return: left_exist, right_exist \n",
    "        Find the existence of neighbor lanes through a very unpleasant hardcoded manner.\n",
    "        1 Overtake Left.\n",
    "        0 Overtake right\n",
    "        Otherwise Return 2, stay in your current lane\n",
    "        '''\n",
    "        if lane_num == 4:\n",
    "            if cur_lane == 2 or cur_lane == 6:\n",
    "                return 1, 0\n",
    "            else:\n",
    "                return 0, 1\n",
    "        elif lane_num == 6:\n",
    "            if cur_lane == 2 or cur_lane == 8:\n",
    "                return 1, 0\n",
    "            elif cur_lane == 3 or cur_lane == 7:\n",
    "                return 1, 1\n",
    "            else:\n",
    "                return 0, 1\n",
    "        elif lane_num == 7:\n",
    "            if cur_lane == 2 or cur_lane == 9:\n",
    "                return 1, 0\n",
    "            elif cur_lane == 3 or cur_lane == 4 or cur_lane == 8:\n",
    "                return 1, 1\n",
    "            else:\n",
    "                return 0, 1\n",
    "\n",
    "    def construct_features(i, frame_num, original_lane):\n",
    "        '''\n",
    "        Construct all the features for the RNN to train:\n",
    "        Here is the list:\n",
    "        Difference of the ego car’s Y position and the lane center: ΔY\n",
    "        Ego car’s X velocity: Vx\n",
    "        Ego car’s Y velocity: Vy\n",
    "        Ego car’s X acceleration: Ax\n",
    "        Ego car’s Y acceleration: Ay\n",
    "        Ego car type: T\n",
    "        TTC of preceding car: TTCp\n",
    "        TTC of following car: TTCf\n",
    "        TTC of left preceding car: TTClp\n",
    "        TTC of left alongside car: TTCla\n",
    "        TTC of left following car: TTClf\n",
    "        TTC of right preceding car: TTCrp\n",
    "        TTC of right alongside car: TTCra\n",
    "        TTC of right following car: TTCrf\n",
    "        '''\n",
    "        going = 0  # 1 left, 2 right\n",
    "        if lane_num == 4:\n",
    "            if original_lane == 2 or original_lane == 3:\n",
    "                going = 1\n",
    "            else:\n",
    "                going = 2\n",
    "        else:\n",
    "            if original_lane == 2 or original_lane == 3 or original_lane == 4 or original_lane == 5:\n",
    "                going = 1\n",
    "            else:\n",
    "                going = 2\n",
    "        cur_feature = {}\n",
    "        cur_feature[\"left_lane_exist\"], cur_feature[\"right_lane_exist\"] = determine_lane_exist(\n",
    "            original_lane)\n",
    "\n",
    "        # We need to consider the fact that right/left are different for top/bottom lanes.\n",
    "        # top lanes are going left      <----\n",
    "        # bottom lanes are going right  ---->\n",
    "        # left -> negative, right -> positive\n",
    "        if going == 1:\n",
    "            cur_feature[\"delta_y\"] = tracks_csv[i][Y][frame_num] - \\\n",
    "                lanes_info[original_lane]  # up\n",
    "            cur_feature[\"y_velocity\"] = -tracks_csv[i][Y_VELOCITY][frame_num]\n",
    "            cur_feature[\"y_acceleration\"] = - \\\n",
    "                tracks_csv[i][Y_ACCELERATION][frame_num]\n",
    "        else:\n",
    "            cur_feature[\"delta_y\"] = lanes_info[original_lane] - \\\n",
    "                tracks_csv[i][Y][frame_num]  # down\n",
    "            cur_feature[\"y_velocity\"] = tracks_csv[i][Y_VELOCITY][frame_num]\n",
    "            cur_feature[\"y_acceleration\"] = tracks_csv[i][Y_ACCELERATION][frame_num]\n",
    "\n",
    "        cur_feature[\"x_velocity\"] = tracks_csv[i][X_VELOCITY][frame_num]\n",
    "        cur_feature[\"x_acceleration\"] = tracks_csv[i][X_ACCELERATION][frame_num]\n",
    "        cur_feature[\"car_type\"] = 1 if tracks_meta[i][CLASS] == \"Car\" else -1\n",
    "\n",
    "        def calculate_ttc(target_car_id):\n",
    "        \n",
    "            \"\"\"\n",
    "            Calculate time to collision of target car and current car\n",
    "            \"\"\"\n",
    "            if target_car_id != 0:\n",
    "                target_frame = tracks_meta[i][INITIAL_FRAME] + \\\n",
    "                    frame_num - tracks_meta[target_car_id][INITIAL_FRAME]\n",
    "                target_x = tracks_csv[target_car_id][X][target_frame]\n",
    "                cur_x = tracks_csv[i][X][frame_num]\n",
    "                target_v = tracks_csv[target_car_id][X_VELOCITY][target_frame]\n",
    "                cur_v = tracks_csv[i][X_VELOCITY][frame_num]\n",
    "                if target_v == cur_v:\n",
    "                    return 99999\n",
    "                if going == 1:\n",
    "                    # going left (up)\n",
    "                    if cur_x > target_x:\n",
    "                        ttc = (cur_x - target_x) / (cur_v - target_v)\n",
    "                    else:\n",
    "                        ttc = (target_x - cur_x) / (target_v - cur_v)\n",
    "                else:\n",
    "                    # going right (down)\n",
    "                    if cur_x > target_x:\n",
    "                        ttc = (cur_x - target_x) / (target_v - cur_v)\n",
    "                    else:\n",
    "                        ttc = (target_x - cur_x) / (cur_v - target_v)\n",
    "                if ttc < 0:\n",
    "                    return 99999\n",
    "                else:\n",
    "                    return ttc\n",
    "            else:\n",
    "                return 99999\n",
    "\n",
    "        # surrounding cars info\n",
    "        cur_feature[\"preceding_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][PRECEDING_ID][frame_num])\n",
    "        cur_feature[\"following_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][FOLLOWING_ID][frame_num])\n",
    "        cur_feature[\"left_preceding_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][LEFT_PRECEDING_ID][frame_num])\n",
    "        cur_feature[\"left_alongside_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][LEFT_ALONGSIDE_ID][frame_num])\n",
    "        cur_feature[\"left_following_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][LEFT_FOLLOWING_ID][frame_num])\n",
    "        cur_feature[\"right_preceding_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][RIGHT_PRECEDING_ID][frame_num])\n",
    "        cur_feature[\"right_alongside_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][RIGHT_ALONGSIDE_ID][frame_num])\n",
    "        cur_feature[\"right_following_ttc\"] = calculate_ttc(\n",
    "            tracks_csv[i][RIGHT_FOLLOWING_ID][frame_num])\n",
    "\n",
    "        ret = tuple(cur_feature.values())\n",
    "        return ret\n",
    "\n",
    "    def detect_lane_change(lane_center, cur_y, lane_width, car_height):\n",
    "        delta_y = abs(lane_center - cur_y)\n",
    "        relative_diff = delta_y / car_height\n",
    "        if(relative_diff < 0.5):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def determine_change_direction(ori_laneId, new_laneId):\n",
    "        '''\n",
    "        return 1 upon left change\n",
    "        return 2 upon right change\n",
    "        '''\n",
    "        if lane_num == 4:\n",
    "            if (ori_laneId == 2 and new_laneId == 3) or (ori_laneId == 6 and new_laneId == 5):\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        else:\n",
    "            # left:\n",
    "            if (ori_laneId == 2 and new_laneId == 3) or (ori_laneId == 4 and new_laneId == 5) \\\n",
    "                or (ori_laneId == 3 and new_laneId == 4) or (ori_laneId == 7 and new_laneId == 6) \\\n",
    "                    or (ori_laneId == 8 and new_laneId == 7) or (ori_laneId == 9 and new_laneId == 8):\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "    # list of list of features\n",
    "    result = []\n",
    "\n",
    "    for i in lane_changing_ids:\n",
    "        # for each car:\n",
    "        last_boundary = 0\n",
    "        # list of (starting index, ending index, direction)\n",
    "        changing_tuple_list = []\n",
    "        # 1. determine the frame we want to use\n",
    "        for frame_num in range(1, len(tracks_csv[i][FRAME])):\n",
    "            if tracks_csv[i][LANE_ID][frame_num] != tracks_csv[i][LANE_ID][frame_num-1]:\n",
    "                original_lane = tracks_csv[i][LANE_ID][frame_num-1]\n",
    "                new_lane = tracks_csv[i][LANE_ID][frame_num]\n",
    "                direction = determine_change_direction(original_lane, new_lane)\n",
    "                # calculate the starting frame\n",
    "                starting_change = frame_num - 1\n",
    "                while starting_change > last_boundary:\n",
    "                    if detect_lane_change(lanes_info[original_lane], tracks_csv[i][Y][starting_change], lane_width, tracks_meta[i][HEIGHT]):\n",
    "                        break\n",
    "                    starting_change -= 1\n",
    "                # calculate the starting and ending frame\n",
    "                if FRAME_BEFORE_FLAG:\n",
    "                    starting_point = starting_change - FRAME_TAKEN - FRAME_BEFORE\n",
    "                    ending_point = starting_change - FRAME_BEFORE\n",
    "                else:\n",
    "                    starting_point = starting_change - FRAME_TAKEN\n",
    "                    ending_point = starting_change\n",
    "                if starting_point > last_boundary:\n",
    "                    changing_tuple_list.append(\n",
    "                        (starting_point, ending_point, direction))\n",
    "                last_boundary = frame_num\n",
    "        # add those frames' features\n",
    "        for pair in changing_tuple_list:\n",
    "            # for each lane change i nstance\n",
    "            cur_change = []\n",
    "            start_idx = pair[0]\n",
    "            end_idx = pair[1]\n",
    "            direction = pair[2]\n",
    "            original_lane = tracks_csv[i][LANE_ID][start_idx]\n",
    "            # continue for out of boundary cases\n",
    "            if original_lane not in lanes_info:\n",
    "                continue\n",
    "            for frame_num in range(start_idx, end_idx):\n",
    "                # construct the object\n",
    "                cur_change.append(construct_features(\n",
    "                    i, frame_num, original_lane))\n",
    "            # add to the result\n",
    "            result.append((cur_change, direction))\n",
    "\n",
    "    change_num = len(result)\n",
    "\n",
    "    if len(lane_keeping_ids) > len(result):\n",
    "        # make the lane keeping size the same as lane changing\n",
    "        lane_keeping_ids = random.sample(lane_keeping_ids, len(result))\n",
    "\n",
    "    for i in lane_keeping_ids:\n",
    "        cur_change = []\n",
    "        original_lane = tracks_csv[i][LANE_ID][0]\n",
    "        fail = False\n",
    "        for frame_num in range(1, FRAME_TAKEN+1):\n",
    "            try:\n",
    "                cur_change.append(construct_features(\n",
    "                    i, frame_num, original_lane))\n",
    "            except:\n",
    "                # handle exception where the total frame is less than FRAME_TAKEN\n",
    "                fail = True\n",
    "                break\n",
    "        if not fail:\n",
    "            result.append((cur_change, 0))\n",
    "\n",
    "    return result, change_num\n",
    "\n",
    "\n",
    "# The result of this is a dataset with the required data necessary to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data processing Functions Overview\n",
    "The following functions Provide a brief overview of the functions implemented above and what each function does \n",
    "<blockquote>\n",
    "    <ol>\n",
    "       <li> determine_lane_exist </li>\n",
    "        <li> construct_features</li>\n",
    "        <li> calculate_ttc</li>\n",
    "        <li> detect_lane_change</li>\n",
    "            Determines whether a vehicle retains its lane, changes to left lane or changes to right lane.\n",
    "        <li> determine_change_direction</li>\n",
    "    </ol>\n",
    "    </blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 84\n",
      "Successfully write to: output/result01.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 166\n",
      "Successfully write to: output/result02.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 243\n",
      "Successfully write to: output/result03.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 418\n",
      "Successfully write to: output/result04.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 594\n",
      "Successfully write to: output/result05.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 793\n",
      "Successfully write to: output/result06.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 885\n",
      "Successfully write to: output/result07.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1072\n",
      "Successfully write to: output/result08.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1230\n",
      "Successfully write to: output/result09.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1324\n",
      "Successfully write to: output/result10.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1432\n",
      "Successfully write to: output/result11.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1565\n",
      "Successfully write to: output/result12.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1751\n",
      "Successfully write to: output/result13.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 1939\n",
      "Successfully write to: output/result14.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2010\n",
      "Successfully write to: output/result15.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2093\n",
      "Successfully write to: output/result16.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2168\n",
      "Successfully write to: output/result17.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2205\n",
      "Successfully write to: output/result18.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2303\n",
      "Successfully write to: output/result19.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2391\n",
      "Successfully write to: output/result20.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2467\n",
      "Successfully write to: output/result21.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2503\n",
      "Successfully write to: output/result22.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2585\n",
      "Successfully write to: output/result23.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2658\n",
      "Successfully write to: output/result24.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2757\n",
      "Successfully write to: output/result25.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 2918\n",
      "Successfully write to: output/result26.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 3072\n",
      "Successfully write to: output/result27.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 3261\n",
      "Successfully write to: output/result28.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 3452\n",
      "Successfully write to: output/result29.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 3665\n",
      "Successfully write to: output/result30.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 3879\n",
      "Successfully write to: output/result31.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4019\n",
      "Successfully write to: output/result32.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4222\n",
      "Successfully write to: output/result33.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4367\n",
      "Successfully write to: output/result34.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4562\n",
      "Successfully write to: output/result35.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4815\n",
      "Successfully write to: output/result36.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 4986\n",
      "Successfully write to: output/result37.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 5186\n",
      "Successfully write to: output/result38.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 5341\n",
      "Successfully write to: output/result39.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 5537\n",
      "Successfully write to: output/result40.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 5701\n",
      "Successfully write to: output/result41.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 5879\n",
      "Successfully write to: output/result42.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 6050\n",
      "Successfully write to: output/result43.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 6237\n",
      "Successfully write to: output/result44.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 6453\n",
      "Successfully write to: output/result45.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 6605\n",
      "Successfully write to: output/result46.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 6753\n",
      "Successfully write to: output/result47.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total changes: 6924\n",
      "Successfully write to: output/result48.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7061\n",
      "Successfully write to: output/result49.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7213\n",
      "Successfully write to: output/result50.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7388\n",
      "Successfully write to: output/result51.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7540\n",
      "Successfully write to: output/result52.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7748\n",
      "Successfully write to: output/result53.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 7939\n",
      "Successfully write to: output/result54.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8078\n",
      "Successfully write to: output/result55.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8243\n",
      "Successfully write to: output/result56.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8441\n",
      "Successfully write to: output/result57.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8530\n",
      "Successfully write to: output/result58.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8602\n",
      "Successfully write to: output/result59.pickle\n",
      "Finished Extracting Tracks Data\n",
      "Finished Extracting Tracks_Metadata\n",
      "Finished Extracting Recording_Metadata\n",
      "total changes: 8803\n",
      "Successfully write to: output/result60.pickle\n"
     ]
    }
   ],
   "source": [
    "# Create an Output file location if none exists\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "    \n",
    "total_change = 0\n",
    "for i in range(1, 61):\n",
    "    number = \"{0:0=2d}\".format(i)\n",
    "    result, change_num = run(number)\n",
    "    total_change += change_num\n",
    "    print(\"total changes:\", total_change)\n",
    "\n",
    "    filename = \"output/result\" + number + \".pickle\"\n",
    "    f = open(filename, 'wb')\n",
    "    pickle.dump(result, f)\n",
    "    print(\"Successfully write to:\", filename)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The stored data takes the folowing format. \n",
    "    ([(x,y,x,.,.,.),(.,.,.,.,)],2).\n",
    "    A tuple containing a list of values and the lane change direction.\n",
    "    1 for left lane change\n",
    "    2 for right change and 0 for cars that retain their individual lane\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'python3_64'",
   "language": "python",
   "name": "64distro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
